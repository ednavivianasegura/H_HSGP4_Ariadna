{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxfH35Zor9PZH/B4P6G2lN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/H_HSGP4_Ariadna/blob/main/Ariadna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzOSglpf0M-T",
        "outputId": "b847393b-ec19-4534-a606-7950ea154e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'H_HSGP4_Ariadna'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 34 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (34/34), 80.27 MiB | 6.67 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# @title **Clonar carpeta GitHub** (Para acceder a módulos y datasets) { form-width: \"5%\", display-mode: \"form\" }\n",
        "# Clona el repositorio\n",
        "try:\n",
        "    !git clone https://github.com/ednavivianasegura/H_HSGP4_Ariadna.git\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Cambiar al directorio \"Curso_PLN\"\n",
        "os.chdir(\"H_HSGP4_Ariadna\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://gitlab.com/libeigen/eigen.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgUOwIpR6fCM",
        "outputId": "ae93a9ed-29d2-4f35-bfcd-e6bdd3206c50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eigen'...\n",
            "remote: Enumerating objects: 124182, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 124182 (delta 191), reused 309 (delta 181), pack-reused 123846\u001b[K\n",
            "Receiving objects: 100% (124182/124182), 105.06 MiB | 20.41 MiB/s, done.\n",
            "Resolving deltas: 100% (102808/102808), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB02Zf2z5cQC",
        "outputId": "d92eb7af-b595-4cf5-ba7b-20584a919616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sinfo\n",
            "  Downloading sinfo-0.3.4.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stdlib_list (from sinfo)\n",
            "  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sinfo\n",
            "  Building wheel for sinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sinfo: filename=sinfo-0.3.4-py3-none-any.whl size=7880 sha256=3c5a1330c27f49cde8f786142b52cc142201e16f9159c69cbf8ce0ad54270e36\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/fe/9d/eb4b47396d5c94b8ad82a5aa9f905c56c981deb4e532329f72\n",
            "Successfully built sinfo\n",
            "Installing collected packages: stdlib_list, sinfo\n",
            "Successfully installed sinfo-0.3.4 stdlib_list-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, sys, gc, random, json, re, shutil\n",
        "from distutils.util import strtobool\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import platform\n",
        "#Validar requisitos del script\n",
        "from sinfo import sinfo\n",
        "import FuncionesAriadnaDL_Noaleatorio as FAVCI\n",
        "\n",
        "Plataforma=platform.platform()\n",
        "print(Plataforma)\n",
        "print(sinfo())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n-PC8ut5XEk",
        "outputId": "d9624a18-c5e9-46a5-a12c-f2ce5ddd61d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.\n",
            "-----\n",
            "FuncionesAriadnaDL_Noaleatorio      NA\n",
            "numpy                               1.25.2\n",
            "pandas                              1.5.3\n",
            "sinfo                               0.3.4\n",
            "tensorflow                          2.15.0\n",
            "-----\n",
            "IPython             7.34.0\n",
            "jupyter_client      6.1.12\n",
            "jupyter_core        5.7.1\n",
            "notebook            6.5.5\n",
            "-----\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "2 logical CPU cores, x86_64\n",
            "-----\n",
            "Session information updated at 2024-03-15 16:59\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Entradas:\n",
        "# Modeling=True if Tensorflow is to be used (The models are created), Modeling=False otherwise\n",
        "Modeling = True # @param {type:\"boolean\"}\n",
        "\n",
        "fore_set = [\"train\",\"test\"] # @param [\"[\\\"train\\\"]\", \"[\\\"valid\\\"]\", \"[\\\"test\\\"]\", \"[\\\"train-valid\\\"]\", \"[\\\"valid-test\\\"]\", \"[\\\"train-valid-test\\\"]\", \"[\\\"train\\\",\\\"test\\\"]\", \"[\\\"train\\\",\\\"valid\\\"]\", \" [\\\"train\\\",\\\"valid\\\",\\\"test\\\"]\", \"[\\\"train\\\",\\\"test\\\",\\\"train-valid-test\\\"]\", \"[\\\"train\\\",\\\"test\\\",\\\"valid-test\\\",\\\"train-valid-test\\\"]\", \"[\\\"train-test\\\"]\", \"[\\\"train\\\",\\\"train-test\\\"]\", \"[\\\"train\\\",\\\"valid-test\\\",\\\"test\\\"]\"] {type:\"raw\"}\n",
        "\n",
        "# In BasesAModelar you can set up an arrangement of bases to perform the learning process.\n",
        "# Intervalo = True is to define an interval, Intervalo = False is to indicate that it is an array of specific series.\n",
        "\n",
        "Intervalo = False # @param {type:\"boolean\"}\n",
        "BasesAModelar = [1,2]\n",
        "\n",
        "# Type of variables:\n",
        "var_set = \"hill\" # @param [\"hill\", \"dln\", \"orb\", \"equi\", \"cart\"]\n",
        "\n",
        "# Especific name for the experiment (to be included in folder name)\n",
        "experimento = \"Prueba\" # @param {type:\"string\"}\n",
        "\n",
        "fachl = 0.5 # @param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "\n",
        "#TYPE OF HYPER-PARAMETER SEARCH\n",
        "method = \"Cartesian\" # @param [\"Cartesian\", \"Random\", \"Especific model\"]\n",
        "\n",
        "# Effective (without starting vector)\n",
        "train_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "valid_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "test_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "# Resolution: [min]\n",
        "resol = 10  # @param {type:\"number\"}\n",
        "\n",
        "# Cross-val (if nfolds!:0 -> valid_set:0)\n",
        "nfolds = 0   # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "# Remove trend\n",
        "rem_trend = False # @param {type:\"boolean\"}\n",
        "\n",
        "path_data = \"data/\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "var_model = \"theta\" # @param {type:\"string\"}\n",
        "\n",
        "var_order= [\"t\",\"r\",\"theta\",\"v\",\"R\",\"THETA\",\"N\"]\n",
        "\n",
        "#############################################################################################################\n",
        "###### SAMPLING CRITERIA\n",
        "#############################################################################################################\n",
        "#Sampling proportional to the stratum size \"SampleMethod\":1 is chosen, \"SampleMethod\":0 otherwise.\n",
        "SampleMethod = True  # @param {type:\"boolean\"}\n",
        "# if SampleMethod=1, one of the hyperparameters should be chosen for stratification, the variable name, must be equal to the name of the hyperparameter defined in ParametersDL\n",
        "VariableToStratify = \"opt\" # @param {type:\"string\"}\n",
        "\n",
        "##########################################################################################################\n",
        "###### HYPER-PARAMETERS DEEP LEARNING\n",
        "##########################################################################################################\n",
        "Parametros = {\n",
        "#ACTIVATION FUNCTION\n",
        "  \"FuncAct\":[\"tanh\",\"linear\",\"elu\",\"relu\"],\n",
        "#BATCH SIZE\n",
        "  \"BachSize\":[64,128,256,512],\n",
        "#NUMBER OF NEURONS IN THE INPUT LAYER\n",
        "  \"NumNeurons\":[8,16,32,64,128,256],\n",
        "#OPTIMIZERS\n",
        "  \"opt\":[\"Adam\", \"Rmsprop\",\"Adadelta\", \"Nadam\"],\n",
        "#loss:\n",
        "  \"loss\":[\"mape\"],\n",
        "#Learning rate:\n",
        "  \"LR\":[1e-05],\n",
        "#Monitor\n",
        "  \"monitor\" : [\"val_loss\"],\n",
        "#NUMBER OF HIDDEN LAYERS\n",
        "  \"HiddenLayers\":[2]\n",
        "    }\n",
        "\n",
        "#Specific configuration:\n",
        "CONFIG =[\n",
        "{\"BachSize\": 64, \"NumNeurons\": 16, \"opt\": \"Rmsprop\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"tanh\", \"FuncAct1\": \"elu\", \"HiddenLayers\": 2},\n",
        "{\"BachSize\": 256, \"NumNeurons\": 64, \"opt\": \"Nadam\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"linear\", \"FuncAct1\": \"tanh\", \"HiddenLayers\": 2},\n",
        "{\"BachSize\": 256, \"NumNeurons\": 32, \"opt\": \"Nadam\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"linear\", \"FuncAct1\": \"tanh\", \"HiddenLayers\": 2}\n",
        "]\n",
        "\n",
        "\n",
        "# Keplerian period: [h] (0 for AUTO)\n",
        "kep_period      = 0\n",
        "\n",
        "# Possibilities: \"num\", \"span\" [h], \"rev\" [rev]\n",
        "input_unit = \"rev\"\n",
        "\n",
        "inputI = 2\n",
        "\n",
        "output_num=1\n",
        "\n",
        "sets_unit=input_unit\n",
        "\n",
        "# Step betconsecutive vectors (1 to maximize no. vectors)\n",
        "vect_step      = 1\n",
        "\n",
        "#max number of epochs\n",
        "epocas = 500  # @param {type:\"number\"}\n",
        "#Patience to find number of Epochs\n",
        "stop_tolerance = 60  # @param {type:\"number\"}\n",
        "#Number of models you create with the same architecture to pick the minimum,  must be greater than 0\n",
        "n_repeats = 10   # @param {type:\"number\"}\n"
      ],
      "metadata": {
        "id": "o7sSy1uh6FQa"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_CreaInfo=time.time()\n",
        "if Intervalo==True:\n",
        "    BasesAModelar=range(BasesAModelar[0],BasesAModelar[1]+1)\n",
        "else:\n",
        "    BasesAModelar=BasesAModelar\n",
        "\n",
        "for h1 in BasesAModelar:\n",
        "\n",
        "    print(var_set+\"-\"+str(h1)+\" Time series modelling.\")\n",
        "    ##########################################################################################################\n",
        "    ###### NAME OF EPHEMERID TO BE STUDIED\n",
        "    ##########################################################################################################\n",
        "    id_expM = var_set+str(h1)\n",
        "    ##########################################################################################################\n",
        "    ###### CREATE NAME OF DIRECTORY WITH PARAMETERS\n",
        "    ##########################################################################################################\n",
        "    experiment=str(experimento)+\"_\"+\"Fachl\"+str(fachl) +\"Me\"+str(method)+\"TrS\"+str(train_set) + \"VaS\"+str(valid_set)+\"TeS\"+str(test_set)+\"Res\"+str(resol)+\"Nf\"+str(nfolds)+\"Rt\"+str(rem_trend) +\"VarS\"+str(var_set)+\"Ep\"+str(epocas)+\"St\"+str(stop_tolerance)+\"VarM\"+str(var_model)\n",
        "    ###########################################################################################################\n",
        "    ###### Create folder name\n",
        "    ###########################################################################################################\n",
        "    Conid_exp = id_expM + experiment\n",
        "    cwd=os.getcwd()\n",
        "    cwd2=cwd\n",
        "    ##########################################################################################################\n",
        "    ###### Configuration of files and folders\n",
        "    ##########################################################################################################\n",
        "    try:\n",
        "      os.stat('KerasPruebasFinal/')\n",
        "    except:\n",
        "      os.mkdir('KerasPruebasFinal/')\n",
        "\n",
        "    path= 'KerasPruebasFinal/'+Conid_exp+'/'\n",
        "\n",
        "    path_results           = \"results/\"\n",
        "    path_out               = \"output/\"\n",
        "    ResumenEjecucion       = path+\"output/Log.txt\"\n",
        "    path_plot              = \"figs/\"\n",
        "    path_models            = \"Modelos/\"\n",
        "    path_cpp               = \"cpp/\"\n",
        "    file_obs               = 'obs'+id_expM+'.out'\n",
        "    file_appr              = 'approx'+id_expM+'.out'\n",
        "    file_BasicPlot         = id_expM +\"_BasicPlot\"\n",
        "    file_plot_Decomp       = id_expM +\"_Decomp\"\n",
        "    file_plot_Complete     = id_expM +\"_Completo\"\n",
        "    fileCandidato          = path+path_results+'Candidatos.csv'\n",
        "    path_path_models       = path+path_models\n",
        "    path_file_obs          = path_data+\"OBS/\"+file_obs\n",
        "    path_file_appr         = path_data+\"APPROX/\"+file_appr\n",
        "    path_file_BasicPlot    = path+path_plot + file_BasicPlot +'.pdf'\n",
        "    fileplotDetrending     = path+path_plot + file_plot_Decomp+\".pdf\"\n",
        "    fileplotComplete       = path+path_plot + file_plot_Complete+\".pdf\"\n",
        "    directorio             = ['figs','Modelos','output','results', \"cpp\"]\n",
        "\n",
        "    #Grid Comfigurations:\n",
        "    hp_all=FAVCI.DeepLerningModelConfigs(Parametros)\n",
        "    NModTotal=len(hp_all)\n",
        "    random.seed(2022)\n",
        "    hp_all=random.sample(hp_all, len(hp_all))\n",
        "\n",
        "    if method==\"Cartesian\":\n",
        "        NModels=NModTotal\n",
        "        hp_all=hp_all\n",
        "        Metodo=\"Cartesiana\"\n",
        "    elif method==\"Random\":\n",
        "        Metodo=\"Aleatoria\"\n",
        "        print(\"Hiper-parameter to sampling: \"+ VariableToStratify)\n",
        "        ListaDeOpciones=Parametros[VariableToStratify]\n",
        "        hp_all=[y for x in ListaDeOpciones for y in hp_all if x==y[VariableToStratify]]\n",
        "        StrVar=[str(hp_all).count(\"'\"+VariableToStratify+\"': '\"+str(n)+\"'\") if type(n)==str else str(hp_all).count(\"'\"+VariableToStratify+\"': \"+str(n)) for n in ListaDeOpciones]\n",
        "\n",
        "        if SampleMethod==0:\n",
        "            if NModels< len(StrVar):\n",
        "                NModels=len(StrVar)\n",
        "            else:\n",
        "                NModels=FAVCI.roundBy(NModels, len(StrVar))\n",
        "            indices=[]\n",
        "            nPerHipePar=round(NModels/len(StrVar))\n",
        "            a=0\n",
        "            for i in StrVar:\n",
        "                random.seed(2022)\n",
        "                indices=indices+random.sample(range(a, i+a), nPerHipePar)\n",
        "                a=i+a\n",
        "            hp_all=[hp_all[index] for index in indices]\n",
        "        else:\n",
        "            indices=[]\n",
        "            nPerHipePar=[round(NModels*(x/sum(StrVar))) for x in StrVar]\n",
        "            a=0\n",
        "            zipped = list(zip(StrVar,nPerHipePar))\n",
        "            for i in zipped:\n",
        "                print(i)\n",
        "                random.seed(2022)\n",
        "                X=random.sample(range(a, i[0]+a), i[1])\n",
        "                indices=indices+X\n",
        "                a=i[0]+a\n",
        "            # indices.sort()\n",
        "            hp_all=[hp_all[index] for index in indices]\n",
        "\n",
        "\n",
        "    elif method==3:\n",
        "        Metodo=\"Modelo Específico\"\n",
        "        # hp_all = [CONFIG]\n",
        "        hp_all = CONFIG\n",
        "        NModels=len(hp_all)\n",
        "\n",
        "    print(\"Total number of possible models: \"+ str(NModTotal)+\"\\n\"+\n",
        "          \"Number of models to find: \"+ str(len(hp_all)))\n",
        "\n",
        "    ###########################################################################################################\n",
        "    ###### FOLDER CREATION AND VALIDATION\n",
        "    ###########################################################################################################\n",
        "    # Check if a folder with the same name as the current experiment already exists.\n",
        "    # If not, a folder with that name is created.\n",
        "    ###########################################################################################################\n",
        "\n",
        "    Verif=path_results\n",
        "\n",
        "    if os.path.exists(path):\n",
        "\n",
        "    ###############################################################\n",
        "    # It is verified that the existing folder is of a complete or\n",
        "    # finished experiment, otherwise it is deleted.\n",
        "    # experiment, otherwise the folder is deleted.\n",
        "    ###############################################################\n",
        "\n",
        "        if os.path.exists(path+Verif) and len(path_path_models)==NModTotal:\n",
        "\n",
        "            sub=1\n",
        "            repeticion=\"\"\n",
        "            NuevoArchivo=\"False\"\n",
        "\n",
        "\n",
        "            while(NuevoArchivo==\"False\"):\n",
        "\n",
        "    #############################################################################\n",
        "    # If the existing folder has a completed experiment\n",
        "    # then folders are searched for folders with the same experiment but\n",
        "    # performed later. What is identified by (i), if found, is\n",
        "    # verify that they are complete. Otherwise, they are deleted and the current\n",
        "    # is assigned that name. \"os.path.exists(path)\" is checked\n",
        "    # again since in each iteration of while, it changes due to \"sub\".\n",
        "    #############################################################################\n",
        "\n",
        "                if  os.path.exists(path):\n",
        "\n",
        "                    if len(os.listdir(path+Verif))>0:\n",
        "                        repeticion=\"(\" +str(sub)+\")\" +'/'\n",
        "                        path= 'KerasPruebasFinal/'+Conid_exp+repeticion\n",
        "                        sub+=1\n",
        "\n",
        "                    else:\n",
        "\n",
        "                        print(f\"Borrando directorio vacio 1 {path}.\"+'\\n')\n",
        "                        shutil.rmtree(path)\n",
        "                        os.mkdir(path)\n",
        "                        os.chdir(path)\n",
        "\n",
        "\n",
        "                        for dir in directorio:\n",
        "                            try:\n",
        "                                os.stat(dir)\n",
        "                            except:\n",
        "                                os.mkdir(dir)\n",
        "\n",
        "                        NuevoArchivo=\"True\"\n",
        "                        os.chdir(cwd2)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    os.mkdir(path)\n",
        "                    os.chdir(path)\n",
        "\n",
        "\n",
        "                    for dir in directorio:\n",
        "                            try:\n",
        "                                os.stat(dir)\n",
        "                            except:\n",
        "                                os.mkdir(dir)\n",
        "                    NuevoArchivo=\"True\"\n",
        "                    os.chdir(cwd2)\n",
        "\n",
        "\n",
        "\n",
        "        elif os.path.exists(path+Verif) and len(path_path_models)<NModTotal:\n",
        "            pass\n",
        "        else:\n",
        "\n",
        "            print(f\"Borrando directorio vacio 2 {path}.\"+'\\n')\n",
        "            shutil.rmtree(path)\n",
        "            os.mkdir(path)\n",
        "            os.chdir(path)\n",
        "\n",
        "\n",
        "            for dir in directorio:\n",
        "\n",
        "                try:\n",
        "                    os.stat(dir)\n",
        "                except:\n",
        "                    os.mkdir(dir)\n",
        "\n",
        "            os.chdir(cwd2)\n",
        "    else:\n",
        "\n",
        "        os.mkdir(path)\n",
        "        os.chdir('KerasPruebasFinal/'+Conid_exp)\n",
        "\n",
        "        for dir in directorio:\n",
        "\n",
        "            try:\n",
        "                os.stat(dir)\n",
        "            except:\n",
        "                os.mkdir(dir)\n",
        "\n",
        "        os.chdir(cwd2)\n",
        "\n",
        "\n",
        "    if not os.path.isfile(path+path_out+\"hp_all.csv\"):\n",
        "        pd.DataFrame(hp_all).to_csv(path+path_out+\"hp_all.csv\")\n",
        "    #########################################################################\n",
        "    #                End of Folder Verification                             #\n",
        "    #########################################################################\n",
        "    if not os.path.isfile(ResumenEjecucion):\n",
        "        Start=str(\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Start modeling: \\n\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Start time: \"+ str(datetime.now()) +\"\\n\"+\n",
        "          \"Folder Name: \"+ str(Conid_exp) +\"\\n\"+\n",
        "          \"Grid Search Method: \" + str(Metodo) + \"\\n\"+\n",
        "          \"Number of models: \"+ str(NModels) +\"\\n\"+\n",
        "          \"Maximum number of epochs: \"+str(epocas)+ \"\\n\"+\n",
        "          \"Stop tolerance: \"+ str(stop_tolerance) +\"\\n\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"#############################################################################\\n\"\n",
        "          )\n",
        "        with open(ResumenEjecucion, 'a') as f:\n",
        "            print(Start\n",
        "          , file=f)\n",
        "        print(Start)\n",
        "\n",
        "    ##########################################################################################################\n",
        "    ###### CREATING DATABASES\n",
        "    ##########################################################################################################\n",
        "    I_bases=time.time()\n",
        "    Bases=FAVCI.creaBases(var_order,path_file_obs,path_file_appr,resol,kep_period,var_set,input_unit,inputI,\n",
        "                          output_num,nfolds,sets_unit,train_set,test_set,var_model,rem_trend,vect_step,\n",
        "                          ResumenEjecucion,valid_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "LGxHT8uz-7G0",
        "outputId": "584e01bf-9959-47ed-973a-59344b9018af"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hill-1 Time series modelling.\n",
            "DeepLerningModelConfigs function time:  0.0\n",
            "\n",
            "Total number of possible models: 1536\n",
            "Number of models to find: 1536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/H_HSGP4_Ariadna/Coordinates.py:421: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  eSinE = (np.multiply(pos,vel)).sum(axis=1) / np.sqrt(mu*a)        # e*sin(E)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-347948ff9624>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m##########################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mI_bases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     Bases=FAVCI.creaBases(var_order,path_file_obs,path_file_appr,resol,kep_period,var_set,input_unit,inputI,\n\u001b[0m\u001b[1;32m    245\u001b[0m                           \u001b[0moutput_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msets_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrem_trend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvect_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                           ResumenEjecucion,valid_set)\n",
            "\u001b[0;32m/content/H_HSGP4_Ariadna/FuncionesAriadnaDL_Noaleatorio.py\u001b[0m in \u001b[0;36mcreaBases\u001b[0;34m(var_order, path_file_obs, path_file_appr, resol, kep_period, var_set, input_unit, inputI, output_num, nfolds, sets_unit, train_set, test_set, var_model, rem_trend, vect_step, ResumenEjecucion, valid_set)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_span_eff\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m       exit(\"The required effective training span (\"+ str(train_span_eff)+ \" h) \"+\n\u001b[0m\u001b[1;32m    594\u001b[0m             \"is negative or zero\")\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eaOjNpBEH9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}