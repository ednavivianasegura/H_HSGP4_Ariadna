{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyx+TPQzsr81O2XAVo86wn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/H_HSGP4_Ariadna/blob/main/Ariadna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzOSglpf0M-T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# @title **Clonar carpeta GitHub** (Para acceder a mÃ³dulos y datasets) { form-width: \"5%\", display-mode: \"form\" }\n",
        "# Clona el repositorio\n",
        "try:\n",
        "    !git clone https://github.com/ednavivianasegura/H_HSGP4_Ariadna.git\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Cambiar al directorio \"Curso_PLN\"\n",
        "os.chdir(\"H_HSGP4_Ariadna\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://gitlab.com/libeigen/eigen.git\n",
        "# !sudo mv eigen /usr/local/include/\n"
      ],
      "metadata": {
        "id": "bgUOwIpR6fCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sinfo"
      ],
      "metadata": {
        "id": "uB02Zf2z5cQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, sys, gc, random, json, re, shutil\n",
        "from distutils.util import strtobool\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import platform\n",
        "#Validar requisitos del script\n",
        "from sinfo import sinfo\n",
        "import FuncionesAriadnaDL_Noaleatorio as FAVCI\n",
        "\n",
        "Plataforma=platform.platform()\n",
        "print(Plataforma)\n",
        "print(sinfo())"
      ],
      "metadata": {
        "id": "5n-PC8ut5XEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Entradas:\n",
        "# Modeling=True if Tensorflow is to be used (The models are created), Modeling=False otherwise\n",
        "Modeling = True # @param {type:\"boolean\"}\n",
        "\n",
        "fore_set = [\"train\",\"test\"] # @param [\"[\\\"train\\\"]\", \"[\\\"valid\\\"]\", \"[\\\"test\\\"]\", \"[\\\"train-valid\\\"]\", \"[\\\"valid-test\\\"]\", \"[\\\"train-valid-test\\\"]\", \"[\\\"train\\\",\\\"test\\\"]\", \"[\\\"train\\\",\\\"valid\\\"]\", \" [\\\"train\\\",\\\"valid\\\",\\\"test\\\"]\", \"[\\\"train\\\",\\\"test\\\",\\\"train-valid-test\\\"]\", \"[\\\"train\\\",\\\"test\\\",\\\"valid-test\\\",\\\"train-valid-test\\\"]\", \"[\\\"train-test\\\"]\", \"[\\\"train\\\",\\\"train-test\\\"]\", \"[\\\"train\\\",\\\"valid-test\\\",\\\"test\\\"]\"] {type:\"raw\"}\n",
        "\n",
        "# In BasesAModelar you can set up an arrangement of bases to perform the learning process.\n",
        "# Intervalo = True is to define an interval, Intervalo = False is to indicate that it is an array of specific series.\n",
        "\n",
        "Intervalo = False # @param {type:\"boolean\"}\n",
        "BasesAModelar = [1,2]\n",
        "\n",
        "# Type of variables:\n",
        "var_set = \"hill\" # @param [\"hill\", \"dln\", \"orb\", \"equi\", \"cart\"]\n",
        "\n",
        "# Especific name for the experiment (to be included in folder name)\n",
        "experimento = \"Prueba\" # @param {type:\"string\"}\n",
        "\n",
        "fachl = 0.5 # @param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "\n",
        "#TYPE OF HYPER-PARAMETER SEARCH\n",
        "method = \"Cartesian\" # @param [\"Cartesian\", \"Random\", \"Especific model\"]\n",
        "\n",
        "# Effective (without starting vector)\n",
        "train_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "valid_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "test_set = 0 # @param {type:\"number\"}\n",
        "\n",
        "# Resolution: [min]\n",
        "resol = 10  # @param {type:\"number\"}\n",
        "\n",
        "# Cross-val (if nfolds!:0 -> valid_set:0)\n",
        "nfolds = 0   # @param {type:\"number\"}\n",
        "\n",
        "plot_width = 10 # @param {type:\"number\"}\n",
        "plot_height = 8 # @param {type:\"number\"}\n",
        "\n",
        "# Remove trend\n",
        "rem_trend = False # @param {type:\"boolean\"}\n",
        "\n",
        "path_data = \"data/\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "var_model = \"theta\" # @param {type:\"string\"}\n",
        "\n",
        "var_order= [\"t\",\"r\",\"theta\",\"v\",\"R\",\"THETA\",\"N\"]\n",
        "\n",
        "var_lab_unit = \"rad\" # @param {type:\"string\"\n",
        "\n",
        "#############################################################################################################\n",
        "###### SAMPLING CRITERIA\n",
        "#############################################################################################################\n",
        "#Sampling proportional to the stratum size \"SampleMethod\":1 is chosen, \"SampleMethod\":0 otherwise.\n",
        "SampleMethod = True  # @param {type:\"boolean\"}\n",
        "# if SampleMethod=1, one of the hyperparameters should be chosen for stratification, the variable name, must be equal to the name of the hyperparameter defined in ParametersDL\n",
        "VariableToStratify = \"opt\" # @param {type:\"string\"}\n",
        "\n",
        "##########################################################################################################\n",
        "###### HYPER-PARAMETERS DEEP LEARNING\n",
        "##########################################################################################################\n",
        "Parametros = {\n",
        "#ACTIVATION FUNCTION\n",
        "  \"FuncAct\":[\"tanh\",\"linear\",\"elu\",\"relu\"],\n",
        "#BATCH SIZE\n",
        "  \"BachSize\":[64,128,256,512],\n",
        "#NUMBER OF NEURONS IN THE INPUT LAYER\n",
        "  \"NumNeurons\":[8,16,32,64,128,256],\n",
        "#OPTIMIZERS\n",
        "  \"opt\":[\"Adam\", \"Rmsprop\",\"Adadelta\", \"Nadam\"],\n",
        "#loss:\n",
        "  \"loss\":[\"mape\"],\n",
        "#Learning rate:\n",
        "  \"LR\":[1e-05],\n",
        "#Monitor\n",
        "  \"monitor\" : [\"val_loss\"],\n",
        "#NUMBER OF HIDDEN LAYERS\n",
        "  \"HiddenLayers\":[2]\n",
        "    }\n",
        "\n",
        "#Specific configuration:\n",
        "CONFIG =[\n",
        "{\"BachSize\": 64, \"NumNeurons\": 16, \"opt\": \"Rmsprop\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"tanh\", \"FuncAct1\": \"elu\", \"HiddenLayers\": 2},\n",
        "{\"BachSize\": 256, \"NumNeurons\": 64, \"opt\": \"Nadam\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"linear\", \"FuncAct1\": \"tanh\", \"HiddenLayers\": 2},\n",
        "{\"BachSize\": 256, \"NumNeurons\": 32, \"opt\": \"Nadam\", \"loss\": \"mape\", \"LR\": 0.0001, \"monitor\": \"val_loss\", \"FuncAct0\": \"linear\", \"FuncAct1\": \"tanh\", \"HiddenLayers\": 2}\n",
        "]\n",
        "\n",
        "\n",
        "# Keplerian period: [h] (0 for AUTO)\n",
        "kep_period      = 0\n",
        "\n",
        "# Possibilities: \"num\", \"span\" [h], \"rev\" [rev]\n",
        "input_unit = \"rev\"\n",
        "\n",
        "inputI = 2\n",
        "\n",
        "output_num=1\n",
        "\n",
        "sets_unit=input_unit\n",
        "\n",
        "# Step betconsecutive vectors (1 to maximize no. vectors)\n",
        "vect_step      = 1\n",
        "\n",
        "#max number of epochs\n",
        "epocas = 500  # @param {type:\"number\"}\n",
        "#Patience to find number of Epochs\n",
        "stop_tolerance = 60  # @param {type:\"number\"}\n",
        "#Number of models you create with the same architecture to pick the minimum,  must be greater than 0\n",
        "n_repeats = 10   # @param {type:\"number\"}\n",
        "verbose = 0 # @param [\"0\", \"1\", \"2\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "Functions            ={\n",
        "    \"relu\":\"{if(x<0) return 0.0;  else return 1.0*(x);});\",\n",
        "    \"tanh\":\"{return tanh(x);});\",\n",
        "    \"linear\":\"{return 1.0*(x);});\",\n",
        "    \"elu\":\"{if(x<0) return 1.0*(exp(x)-1); else return 1.0*(x);});\",\n",
        "    \"sigmoid\":\"{return 1/(1+exp(-x));});\"\n",
        "    }\n",
        "t_dist = [2,4,6,8,10,12,14,20,30]\n",
        "var_angular= True # @param {type:\"boolean\"}\n",
        "PathEIGEN = \"eigen\" # @param {type:\"string\"}\n",
        "Forecast= True # @param {type:\"boolean\"}\n"
      ],
      "metadata": {
        "id": "o7sSy1uh6FQa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_CreaInfo=time.time()\n",
        "if Intervalo==True:\n",
        "    BasesAModelar=range(BasesAModelar[0],BasesAModelar[1]+1)\n",
        "else:\n",
        "    BasesAModelar=BasesAModelar\n",
        "\n",
        "for h1 in BasesAModelar:\n",
        "\n",
        "    print(var_set+\"-\"+str(h1)+\" Time series modelling.\")\n",
        "    ##########################################################################################################\n",
        "    ###### NAME OF EPHEMERID TO BE STUDIED\n",
        "    ##########################################################################################################\n",
        "    id_expM = var_set+str(h1)\n",
        "    ##########################################################################################################\n",
        "    ###### CREATE NAME OF DIRECTORY WITH PARAMETERS\n",
        "    ##########################################################################################################\n",
        "    experiment=str(experimento)+\"_\"+\"Fachl\"+str(fachl) +\"Me\"+str(method)+\"TrS\"+str(train_set) + \"VaS\"+str(valid_set)+\"TeS\"+str(test_set)+\"Res\"+str(resol)+\"Nf\"+str(nfolds)+\"Rt\"+str(rem_trend) +\"VarS\"+str(var_set)+\"Ep\"+str(epocas)+\"St\"+str(stop_tolerance)+\"VarM\"+str(var_model)\n",
        "    ###########################################################################################################\n",
        "    ###### Create folder name\n",
        "    ###########################################################################################################\n",
        "    Conid_exp = id_expM + experiment\n",
        "    cwd=os.getcwd()\n",
        "    cwd2=cwd\n",
        "    ##########################################################################################################\n",
        "    ###### Configuration of files and folders\n",
        "    ##########################################################################################################\n",
        "    try:\n",
        "      os.stat('KerasPruebasFinal/')\n",
        "    except:\n",
        "      os.mkdir('KerasPruebasFinal/')\n",
        "\n",
        "    path= 'KerasPruebasFinal/'+Conid_exp+'/'\n",
        "\n",
        "    path_results           = \"results/\"\n",
        "    path_out               = \"output/\"\n",
        "    ResumenEjecucion       = path+\"output/Log.txt\"\n",
        "    path_plot              = \"figs/\"\n",
        "    path_models            = \"Modelos/\"\n",
        "    path_cpp               = \"cpp/\"\n",
        "    file_obs               = 'obs'+id_expM+'.out'\n",
        "    file_appr              = 'approx'+id_expM+'.out'\n",
        "    file_BasicPlot         = id_expM +\"_BasicPlot\"\n",
        "    file_plot_Decomp       = id_expM +\"_Decomp\"\n",
        "    file_plot_Complete     = id_expM +\"_Completo\"\n",
        "    fileCandidato          = path+path_results+'Candidatos.csv'\n",
        "    path_path_models       = path+path_models\n",
        "    path_file_obs          = path_data+\"OBS/\"+file_obs\n",
        "    path_file_appr         = path_data+\"APPROX/\"+file_appr\n",
        "    path_file_BasicPlot    = path+path_plot + file_BasicPlot +'.pdf'\n",
        "    fileplotDetrending     = path+path_plot + file_plot_Decomp+\".pdf\"\n",
        "    fileplotComplete       = path+path_plot + file_plot_Complete+\".pdf\"\n",
        "    directorio             = ['figs','Modelos','output','results', \"cpp\"]\n",
        "\n",
        "    #Grid Comfigurations:\n",
        "    hp_all=FAVCI.DeepLerningModelConfigs(Parametros)\n",
        "    NModTotal=len(hp_all)\n",
        "    random.seed(2022)\n",
        "    hp_all=random.sample(hp_all, len(hp_all))\n",
        "\n",
        "    if method==\"Cartesian\":\n",
        "        NModels=NModTotal\n",
        "        hp_all=hp_all\n",
        "        Metodo=\"Cartesiana\"\n",
        "    elif method==\"Random\":\n",
        "        Metodo=\"Aleatoria\"\n",
        "        print(\"Hiper-parameter to sampling: \"+ VariableToStratify)\n",
        "        ListaDeOpciones=Parametros[VariableToStratify]\n",
        "        hp_all=[y for x in ListaDeOpciones for y in hp_all if x==y[VariableToStratify]]\n",
        "        StrVar=[str(hp_all).count(\"'\"+VariableToStratify+\"': '\"+str(n)+\"'\") if type(n)==str else str(hp_all).count(\"'\"+VariableToStratify+\"': \"+str(n)) for n in ListaDeOpciones]\n",
        "\n",
        "        if SampleMethod==0:\n",
        "            if NModels< len(StrVar):\n",
        "                NModels=len(StrVar)\n",
        "            else:\n",
        "                NModels=FAVCI.roundBy(NModels, len(StrVar))\n",
        "            indices=[]\n",
        "            nPerHipePar=round(NModels/len(StrVar))\n",
        "            a=0\n",
        "            for i in StrVar:\n",
        "                random.seed(2022)\n",
        "                indices=indices+random.sample(range(a, i+a), nPerHipePar)\n",
        "                a=i+a\n",
        "            hp_all=[hp_all[index] for index in indices]\n",
        "        else:\n",
        "            indices=[]\n",
        "            nPerHipePar=[round(NModels*(x/sum(StrVar))) for x in StrVar]\n",
        "            a=0\n",
        "            zipped = list(zip(StrVar,nPerHipePar))\n",
        "            for i in zipped:\n",
        "                print(i)\n",
        "                random.seed(2022)\n",
        "                X=random.sample(range(a, i[0]+a), i[1])\n",
        "                indices=indices+X\n",
        "                a=i[0]+a\n",
        "            # indices.sort()\n",
        "            hp_all=[hp_all[index] for index in indices]\n",
        "\n",
        "\n",
        "    elif method==3:\n",
        "        Metodo=\"Modelo EspecÃ­fico\"\n",
        "        # hp_all = [CONFIG]\n",
        "        hp_all = CONFIG\n",
        "        NModels=len(hp_all)\n",
        "\n",
        "    print(\"Total number of possible models: \"+ str(NModTotal)+\"\\n\"+\n",
        "          \"Number of models to find: \"+ str(len(hp_all)))\n",
        "\n",
        "    ###########################################################################################################\n",
        "    ###### FOLDER CREATION AND VALIDATION\n",
        "    ###########################################################################################################\n",
        "    # Check if a folder with the same name as the current experiment already exists.\n",
        "    # If not, a folder with that name is created.\n",
        "    ###########################################################################################################\n",
        "\n",
        "    Verif=path_results\n",
        "\n",
        "    if os.path.exists(path):\n",
        "\n",
        "    ###############################################################\n",
        "    # It is verified that the existing folder is of a complete or\n",
        "    # finished experiment, otherwise it is deleted.\n",
        "    # experiment, otherwise the folder is deleted.\n",
        "    ###############################################################\n",
        "\n",
        "        if os.path.exists(path+Verif) and len(path_path_models)==NModTotal:\n",
        "\n",
        "            sub=1\n",
        "            repeticion=\"\"\n",
        "            NuevoArchivo=\"False\"\n",
        "\n",
        "\n",
        "            while(NuevoArchivo==\"False\"):\n",
        "\n",
        "    #############################################################################\n",
        "    # If the existing folder has a completed experiment\n",
        "    # then folders are searched for folders with the same experiment but\n",
        "    # performed later. What is identified by (i), if found, is\n",
        "    # verify that they are complete. Otherwise, they are deleted and the current\n",
        "    # is assigned that name. \"os.path.exists(path)\" is checked\n",
        "    # again since in each iteration of while, it changes due to \"sub\".\n",
        "    #############################################################################\n",
        "\n",
        "                if  os.path.exists(path):\n",
        "\n",
        "                    if len(os.listdir(path+Verif))>0:\n",
        "                        repeticion=\"(\" +str(sub)+\")\" +'/'\n",
        "                        path= 'KerasPruebasFinal/'+Conid_exp+repeticion\n",
        "                        sub+=1\n",
        "\n",
        "                    else:\n",
        "\n",
        "                        print(f\"Borrando directorio vacio 1 {path}.\"+'\\n')\n",
        "                        shutil.rmtree(path)\n",
        "                        os.mkdir(path)\n",
        "                        os.chdir(path)\n",
        "\n",
        "\n",
        "                        for dir in directorio:\n",
        "                            try:\n",
        "                                os.stat(dir)\n",
        "                            except:\n",
        "                                os.mkdir(dir)\n",
        "\n",
        "                        NuevoArchivo=\"True\"\n",
        "                        os.chdir(cwd2)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    os.mkdir(path)\n",
        "                    os.chdir(path)\n",
        "\n",
        "\n",
        "                    for dir in directorio:\n",
        "                            try:\n",
        "                                os.stat(dir)\n",
        "                            except:\n",
        "                                os.mkdir(dir)\n",
        "                    NuevoArchivo=\"True\"\n",
        "                    os.chdir(cwd2)\n",
        "\n",
        "\n",
        "\n",
        "        elif os.path.exists(path+Verif) and len(path_path_models)<NModTotal:\n",
        "            pass\n",
        "        else:\n",
        "\n",
        "            print(f\"Borrando directorio vacio 2 {path}.\"+'\\n')\n",
        "            shutil.rmtree(path)\n",
        "            os.mkdir(path)\n",
        "            os.chdir(path)\n",
        "\n",
        "\n",
        "            for dir in directorio:\n",
        "\n",
        "                try:\n",
        "                    os.stat(dir)\n",
        "                except:\n",
        "                    os.mkdir(dir)\n",
        "\n",
        "            os.chdir(cwd2)\n",
        "    else:\n",
        "\n",
        "        os.mkdir(path)\n",
        "        os.chdir('KerasPruebasFinal/'+Conid_exp)\n",
        "\n",
        "        for dir in directorio:\n",
        "\n",
        "            try:\n",
        "                os.stat(dir)\n",
        "            except:\n",
        "                os.mkdir(dir)\n",
        "\n",
        "        os.chdir(cwd2)\n",
        "\n",
        "\n",
        "    if not os.path.isfile(path+path_out+\"hp_all.csv\"):\n",
        "        pd.DataFrame(hp_all).to_csv(path+path_out+\"hp_all.csv\")\n",
        "    #########################################################################\n",
        "    #                End of Folder Verification                             #\n",
        "    #########################################################################\n",
        "    if not os.path.isfile(ResumenEjecucion):\n",
        "        Start=str(\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Start modeling: \\n\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Start time: \"+ str(datetime.now()) +\"\\n\"+\n",
        "          \"Folder Name: \"+ str(Conid_exp) +\"\\n\"+\n",
        "          \"Grid Search Method: \" + str(Metodo) + \"\\n\"+\n",
        "          \"Number of models: \"+ str(NModels) +\"\\n\"+\n",
        "          \"Maximum number of epochs: \"+str(epocas)+ \"\\n\"+\n",
        "          \"Stop tolerance: \"+ str(stop_tolerance) +\"\\n\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"#############################################################################\\n\"\n",
        "          )\n",
        "        with open(ResumenEjecucion, 'a') as f:\n",
        "            print(Start\n",
        "          , file=f)\n",
        "        print(Start)\n",
        "\n",
        "    ##########################################################################################################\n",
        "    ###### CREATING DATABASES\n",
        "    ##########################################################################################################\n",
        "    I_bases=time.time()\n",
        "    Bases=FAVCI.creaBases(var_order,path_file_obs,path_file_appr,resol,kep_period,var_set,input_unit,inputI,\n",
        "                          output_num,nfolds,sets_unit,train_set,test_set,var_model,rem_trend,vect_step,\n",
        "                          ResumenEjecucion,valid_set)\n",
        "    ind_train=Bases[0]\n",
        "    train_seq=Bases[1]\n",
        "    train_seq_num=Bases[2]\n",
        "    train_trend_seq=Bases[3]\n",
        "    train_vect=Bases[4]\n",
        "    ind_valid=Bases[5]\n",
        "    ind_valid0=Bases[6]\n",
        "    valid_seq=Bases[7]\n",
        "    valid_seq_num=Bases[8]\n",
        "    valid_trend_seq=Bases[9]\n",
        "    valid_vect=Bases[10]\n",
        "    ind_test=Bases[11]\n",
        "    ind_test0=Bases[12]\n",
        "    test_seq=Bases[13]\n",
        "    test_trend_seq=Bases[15]\n",
        "    appr=Bases[16]\n",
        "    obs=Bases[17]\n",
        "    error=Bases[18]\n",
        "    error_comps=Bases[19]\n",
        "    error_trend=Bases[20]\n",
        "    errorBU=Bases[21]\n",
        "    input_num=Bases[22]\n",
        "\n",
        "    print('Time creating data '+str(int(time.time()-I_bases))+' sec'+'\\n')\n",
        "\n",
        "    ##########################################################################################################\n",
        "    ###### MAIN GRAPHICS\n",
        "    ##########################################################################################################\n",
        "    g_time=time.time()\n",
        "\n",
        "    if not os.path.isfile(path_file_BasicPlot):\n",
        "        FAVCI.BasicPlot(var_model,path_file_BasicPlot,plot_width,plot_height,train_seq,input_num,\n",
        "                        output_num,train_seq_num,test_seq,nfolds,valid_seq,var_lab_unit)\n",
        "\n",
        "    if (rem_trend):\n",
        "\n",
        "        train_seq_t  =  pd.concat([train_seq['t'], train_seq[var_model]-train_trend_seq[var_model]], axis=1)\n",
        "        valid_seq_t  =  pd.concat([valid_seq['t'], valid_seq[var_model]-valid_trend_seq[var_model]], axis=1)\n",
        "        test_seq_t   =  pd.concat([test_seq['t'], test_seq[var_model]-test_trend_seq[var_model]], axis=1)\n",
        "\n",
        "        if not os.path.isfile(fileplotDetrending):\n",
        "            FAVCI.plot_decomp(fileplotDetrending,error_comps)\n",
        "        if not os.path.isfile(fileplotComplete):\n",
        "            FAVCI.plot_complete(fileplotComplete,errorBU,var_model,error_trend,error,var_lab_unit)\n",
        "\n",
        "        FAVCI.BasicPlot(var_model,path_file_BasicPlot,plot_width,plot_height,train_seq_t,input_num,\n",
        "                        output_num,train_seq_num,test_seq_t,nfolds,valid_seq_t,var_lab_unit)\n",
        "\n",
        "    print('Time main graphics '+str(int(time.time()-g_time))+' sec'+'\\n')\n",
        "\n",
        "    ##########################################################################################################\n",
        "    ###### Call KERAS.SERIE function (Tensorflow + keras)\n",
        "    ##########################################################################################################\n",
        "\n",
        "    collected = gc.collect()\n",
        "    print(\"Garbage collector start: collected %d objects.\" % (collected))\n",
        "\n",
        "\n",
        "    ###########################################################################################################\n",
        "    ###########################################################################################################\n",
        "    #### Modelling ####\n",
        "    I_Modelado=time.time()\n",
        "    if Modeling==1:\n",
        "        for lista in hp_all:\n",
        "\n",
        "            Candidatos= FAVCI.KerasSerie(train_vect,valid_vect,fileCandidato,path_path_models,\n",
        "                           n_repeats,lista,input_num,fachl,stop_tolerance,epocas,\n",
        "                          nfolds,path,path_plot,verbose,var_order,path_file_obs,\n",
        "                          path_file_appr,resol,kep_period,var_set,input_unit,inputI,\n",
        "                          output_num,sets_unit,train_set,valid_set,test_set,var_model,\n",
        "                          var_angular,rem_trend,vect_step,ResumenEjecucion,t_dist,\n",
        "                          PathEIGEN,Functions,path_cpp)\n",
        "            print(\"Length Candidates: \"+str(Candidatos.shape[0]))\n",
        "            collected = gc.collect()\n",
        "            print(\"Garbage collector end: collected %d objects.\" % (collected))\n",
        "\n",
        "            gc.get_count()\n",
        "            gc.collect()\n",
        "            gc.get_count()\n",
        "\n",
        "        print(\"Modeling time: \", str(round(time.time()-I_Modelado,2))+'\\n')\n",
        "    else:\n",
        "\n",
        "        ModStr=str(\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Candidatos file has been imported (Not modelling)\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"Start time again: \"+ str(datetime.now()) +\"\\n\"+\n",
        "          \"Folder Name: \"+ str(Conid_exp) +\"\\n\"+\n",
        "          \"#############################################################################\\n\"+\n",
        "          \"#############################################################################\\n\"\n",
        "          )\n",
        "\n",
        "        with open(ResumenEjecucion) as f:\n",
        "            if not 'Candidatos file has been imported' in f.read():\n",
        "                with open(ResumenEjecucion, 'a') as f:\n",
        "                    print(ModStr, file=f)\n",
        "        print(ModStr)\n",
        "        if os.path.isfile(fileCandidato):\n",
        "            Candidatos=pd.read_csv(fileCandidato, index_col=0)\n",
        "###########################################################################################################\n",
        "###########################################################################################################\n",
        "#### Forecasting ####\n",
        "\n",
        "    I_Forecasting=time.time()\n",
        "    filenamedistKMHyb=path+path_results+\"DistKMhyb.xlsx\"\n",
        "    # RMSE = pd.DataFrame(columns=[\"FileName\",\"Rmse_Epsilon\",\"Hill\", \"fore_set\"])\n",
        "\n",
        "\n",
        "    if not os.path.isfile(filenamedistKMHyb):\n",
        "        DistKMhybF = pd.DataFrame(columns=[\"Valida\"])\n",
        "    else:\n",
        "        DistKMhybF = pd.read_excel(filenamedistKMHyb,engine='openpyxl', index_col=0)\n",
        "\n",
        "#Create file \"LeerPesosdetxt.h\"\n",
        "\n",
        "    if not os.path.isfile(path_path_models+\"LeerPesosdetxt.h\"):\n",
        "        FAVCI.LeerPesosdetxt(\"\",path_path_models)\n",
        "\n",
        "    for m in Candidatos.index:\n",
        "        mini=time.time()\n",
        "        lista=Candidatos.iloc[m,Candidatos.columns == 'Candidato'].values[0]\n",
        "        FileName = \"modelo\"+str(m)\n",
        "        Mod=tf.keras.models.load_model(path_path_models+FileName+\".h5\", compile=False)\n",
        "\n",
        "        #Extract Model information\n",
        "        NCapas,Act,K=FAVCI.ExtractModInfo(Mod,ResumenEjecucion)\n",
        "\n",
        "        for fores in fore_set:\n",
        "            filenamedistKMAppr=path+path_results+\"DistKMAppr\"+fores+\".xlsx\"\n",
        "            filenamedistKMApprBest=path+path_results+\"DistKMApprBest\"+fores+\".xlsx\"\n",
        "            Valida=str(lista)+\"_\"+fores+\"_m_\"+str(m)\n",
        "            if not Valida in list(DistKMhybF[\"Valida\"]):\n",
        "                ini=time.time()\n",
        "                fore_seq,fore_test,obs_test,appr_test,fore_trend_seq,Reales,Reales_trend=FAVCI.Select_fore_set(fores,\n",
        "                ind_train,nfolds,ind_valid0,train_seq_num,input_num,output_num,\n",
        "                ind_test0,valid_seq_num,error,errorBU,error_trend,ind_valid,ind_test,obs,appr,var_model)\n",
        "\n",
        "                #Export input files for C++ execution\n",
        "                FAVCI.ExportDataInputCMasMas(\"\",path_path_models,fore_seq,input_num,K,Mod)\n",
        "    ###########################################################################################################\n",
        "                Epsilon=Reales.loc[input_num:,var_model]\n",
        "                Epsilon.to_csv(path+path_results+\"Epsilon\"+fores+\".csv\")\n",
        "\n",
        "                #creando modelo c++\n",
        "                #Crea archivo LeerPesosdetxt.h\n",
        "                Inicio=time.time()\n",
        "                if not os.path.isfile(path_path_models+\"LeerPesosdetxt.h\"):\n",
        "                    FAVCI.LeerPesosdetxt(\"\",path_path_models)\n",
        "\n",
        "\n",
        "                ######################################\n",
        "                #### Crea archivo RedNeuronal.cpp\n",
        "                if not os.path.isfile(path_path_models+FileName+\".cpp\"):\n",
        "                    FAVCI.creaRedNeuronalcMasMas(path_path_models+FileName+\".cpp\",K,Act,NCapas,Functions)\n",
        "                ######################################\n",
        "\n",
        "                ######################################\n",
        "                #### Compile RedNeuronal.cpp file\n",
        "                Inicio=time.time()\n",
        "                Plataforma=platform.platform()\n",
        "                if Plataforma.find(\"indows\") == 1:\n",
        "                    FileVerification=FileName+\".exe\"\n",
        "                else:\n",
        "                    FileVerification=FileName\n",
        "                if not os.path.isfile(path+path_cpp+FileVerification):\n",
        "                    cwd=os.getcwd()\n",
        "                    cwd2=cwd\n",
        "                    os.chdir(os.path.abspath(path_path_models))\n",
        "\n",
        "                    #O1, O2 or O3 can be used. As it increases it loses accuracy.\n",
        "                    if Plataforma.find(\"indows\") == 1:\n",
        "                        pl=subprocess.Popen(r\"g++ -O2 -I EINGEN/eigen/ \"+FileName+ \".cpp -o \"+FileName,shell=True)\n",
        "                    else:\n",
        "                        pl=subprocess.Popen(r\"g++ -std=c++0x -O2 -I EINGEN/eigen/ \"+FileName+ \".cpp -o \"+FileName,shell=True)\n",
        "                    pl.wait()\n",
        "                    os.chdir(cwd2)\n",
        "                ##############################################\n",
        "\n",
        "                fore_timeI=time.time()\n",
        "                DistKMAppr,DistKMApprBest,DistKMhyb,Fore,Cols=FAVCI.forec(t_dist,fore_seq,obs_test,appr_test, Mod,fore_test,m,input_num,\n",
        "                          output_num,var_model,var_angular,var_set,FileName,Functions,\"\",path_path_models)\n",
        "                fin=time.time()\n",
        "\n",
        "                #RMSE:\n",
        "\n",
        "                Epsilon_Fore=Fore.loc[input_num:,var_model]\n",
        "                Epsilon_Fore.to_csv(path+path_results+\"Epsilon_Fore\"+fores+str(m)+\".csv\")\n",
        "                Rmse_Epsilon=FAVCI.RMSE(Epsilon, Epsilon_Fore)\n",
        "\n",
        "\n",
        "                print(\"Modeling + forecasting time: \", str(round(fin-ini,2))+'\\n')\n",
        "    ###########################################################################################################\n",
        "                DistKMhyb[DistKMhyb == 0] = np.nan\n",
        "                DistKMhyb[\"Avg_Days_Km\"]=DistKMhyb[Cols].mean(axis=1,skipna = True)\n",
        "                DistKMhyb[\"fore_set\"]=fores\n",
        "                DistKMhyb[\"Valida\"]=Valida\n",
        "                DistKMhyb[\"Valida\"]=Valida\n",
        "                DistKMhyb[\"Time\"]=round(time.time()-fore_timeI,2)\n",
        "                DistKMhyb[\"Rmse_Epsilon\"]=Rmse_Epsilon\n",
        "\n",
        "\n",
        "                if not os.path.isfile(filenamedistKMAppr):\n",
        "                    DistKMAppr=DistKMAppr.to_excel(filenamedistKMAppr, index = True)\n",
        "                if not os.path.isfile(filenamedistKMApprBest):\n",
        "                    DistKMApprBest=DistKMApprBest.to_excel(filenamedistKMApprBest, index = True)\n",
        "\n",
        "                if (rem_trend):\n",
        "                    Fore[var_model]  = Fore[var_model] + fore_trend_seq[var_model]\n",
        "                    Reales           = Reales_trend\n",
        "\n",
        "                DistKMhybF=DistKMhybF.append(DistKMhyb)\n",
        "                DistKMhybF.to_excel(filenamedistKMHyb, index = True)\n",
        "\n",
        "                nombregrafico=path+path_plot+id_expM +\"_\"+fores+\"_m_\"+str(m)\n",
        "                if not os.path.isfile(nombregrafico):\n",
        "                    FAVCI.plot_fore(Fore,Reales,nombregrafico,plot_width,plot_height,input_num,output_num,var_model,var_lab_unit)\n",
        "\n",
        "                if os.path.isfile(path_path_models+\"Entrada.csv\"):\n",
        "                    os.remove(path_path_models+\"Entrada.csv\")\n",
        "                if os.path.isfile(path_path_models+'NumeroDatos.txt'):\n",
        "                    os.remove(path_path_models+'NumeroDatos.txt')\n",
        "                if os.path.isfile(path_path_models+\"Fore.dat\"):\n",
        "                    os.remove(path_path_models+\"Fore.dat\")\n",
        "\n",
        "                collected = gc.collect()\n",
        "                print(\"Garbage collector FORECASTING: collected %d objects.\" % (collected))\n",
        "\n",
        "                gc.get_count()\n",
        "                gc.collect()\n",
        "                gc.get_count()\n",
        "\n",
        "        #Del c++ inputs files\n",
        "        for k in K:\n",
        "            a_file = path_path_models+k+\".csv\"\n",
        "            if os.path.isfile(a_file):\n",
        "                os.remove(a_file)\n",
        "        gc.get_count()\n",
        "        gc.collect()\n",
        "        gc.get_count()\n",
        "\n",
        "    print(\"Fore time: \", str(round(time.time()-I_Forecasting,2))+'\\n')\n",
        "\n",
        "    #Eliminar carpeta Eigen\n",
        "    if os.path.exists(path_path_models+\"EINGEN\"):\n",
        "        try:\n",
        "            shutil.rmtree(path_path_models+\"EINGEN\")\n",
        "            print('EINGEN directory deleted')\n",
        "        except OSError as err:\n",
        "            print(\"Except: \\n\")\n",
        "            print(err)\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "### SUMMARY:\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\n",
        "    if not method==3 and Forecast==True:\n",
        "        with open(ResumenEjecucion) as f:\n",
        "            if 'BEST MODEL' in f.read():\n",
        "                # Delete some text in a text file\n",
        "                orig_file = open(ResumenEjecucion, \"r\")\n",
        "                lines = orig_file.readlines()\n",
        "\n",
        "                start = False\n",
        "                saved_list = []\n",
        "                for rec in lines:\n",
        "                    if \"BEST MODEL:\" in rec:\n",
        "                        start = True\n",
        "                    if not start:\n",
        "                        saved_list.append(rec)\n",
        "                    if \"BEST MODEL END\" in rec:\n",
        "                        start= False\n",
        "\n",
        "                new_text_file = open(ResumenEjecucion, \"w\")\n",
        "                new_text_file.writelines(saved_list)\n",
        "                new_text_file.close()\n",
        "\n",
        "        Mejor=pd.DataFrame(Candidatos.sort_values(by=['errorAvgDays'])).head(1)\n",
        "        try:\n",
        "            Resumen=str(\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"BEST MODEL: \\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"The total time spent performing the gird search \"+ Metodo +\"of \"+str(Candidatos.shape[0])+\" models is: \"+ str(sum([Candidatos[\"time\"][a] for a in Candidatos.index if type(Candidatos[\"time\"][a])!=str]))+ \" seconds \\n\"+\n",
        "              \"The total forecast time is: \"+ str(sum(DistKMhybF[\"Time\"]))+ \" seconds \\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"The best candidate is: \\n\" + str(Mejor[\"Candidato\"].values[0]) +\"\\n\"+\n",
        "              \"Such as: \\n\"+\n",
        "              \"Error\" + Mejor[\"Candidato\"].values[0][\"loss\"] + \" is: \"+ str(Mejor[\"Error\"].values[0])+\"\\n\"+\n",
        "              \"Average error in distance is: \"+str(Mejor[\"errorAvgDays\"].values[0])+\"\\n\"\n",
        "              \"Number of epochs is : \"+str(Mejor[\"Epochs\"].values[0])+\"\\n\"+\n",
        "              \"Model name is \"+str(Mejor[\"Nombre\"].values[0])+\"\\n\"+\n",
        "              \"End time: \"+ str(datetime.now()) +\"\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"BEST MODEL END \\n\")\n",
        "        except:\n",
        "            Resumen=str(\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"BEST MODEL: \\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"The total time spent performing the grid search  \"+ Metodo +\"of \"+str(Candidatos.shape[0])+\" models is: \"+ str(sum([Candidatos[\"time\"][a] for a in Candidatos.index if type(Candidatos[\"time\"][a])!=str]))+ \" seconds \\n\"+\n",
        "              \"The total forecast time is: \"+ str(sum(DistKMhybF[\"Time\"]))+ \" seconds \\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"The best candidate is: \\n\" + str(Mejor[\"Candidato\"].values[0]) +\"\\n\"+\n",
        "              \"Such as: \\n\"+\n",
        "              \"Error\" + re.search('%s(.*)%s' % (\"'loss':\", \", 'LR'\"), Mejor[\"Candidato\"].values[0]).group(1) + \" is: \"+ str(Mejor[\"Error\"].values[0])+\"\\n\"+\n",
        "              \"Average error in distance is: \"+str(Mejor[\"errorAvgDays\"].values[0])+\"\\n\"\n",
        "              \"Number of epochs is : \"+str(Mejor[\"Epochs\"].values[0])+\"\\n\"+\n",
        "              \"Model name is \"+str(Mejor[\"Nombre\"].values[0])+\"\\n\"+\n",
        "              \"End time: \"+ str(datetime.now()) +\"\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"#############################################################################\\n\"+\n",
        "              \"BEST MODEL END \\n\")\n",
        "        with open(ResumenEjecucion, 'a') as f:\n",
        "            print(Resumen\n",
        "          , file=f)\n",
        "        print(Resumen)\n",
        "\n",
        "print(\"Hora inicio:\")\n",
        "print(\"Hora fin:\")\n",
        "print(datetime.now())\n",
        "\n",
        "\n",
        "#Eliminar carpeta Eigen\n",
        "if os.path.exists(path+path_cpp+\"EINGEN\"):\n",
        "    try:\n",
        "        shutil.rmtree(path+path_cpp+\"EINGEN\")\n",
        "        print('EINGEN directory deleted')\n",
        "    except OSError as err:\n",
        "        print(\"Except: \\n\")\n",
        "        print(err)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LGxHT8uz-7G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/H_HSGP4_Ariadna/KerasPruebasFinal/hill1Prueba_Fachl0.5MeCartesianTrS0VaS0TeS0Res10Nf0RtFalseVarShillEp500St60VarMtheta/cpp\")"
      ],
      "metadata": {
        "id": "2eaOjNpBEH9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57jYx1oKfJhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n"
      ],
      "metadata": {
        "id": "Qb0HY1QLfdtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run='g++ aa.cpp -o traincpp0'\n",
        "pl=subprocess.Popen(run,shell=True)\n",
        "print(f\"EjecuciÃ³n: {pl.wait()}\")"
      ],
      "metadata": {
        "id": "YrbCe2PBgqOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -std=c++0x -O2 -I \"/content/H_HSGP4_Ariadna/KerasPruebasFinal/hill1Prueba_Fachl0.5MeCartesianTrS0VaS0TeS0Res10Nf0RtFalseVarShillEp500St60VarMtheta/cpp/eigen\" aa.cpp -o traincpp0"
      ],
      "metadata": {
        "id": "1xJdbsHLhCWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}